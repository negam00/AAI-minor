{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nnfs.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1x6cNgTsa24c3CSHaNDgHaf7plri1N13I","authorship_tag":"ABX9TyMLuLOrX8arO31ZkCTX4lIR"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"pycharm":{"is_executing":false},"id":"yKqZtCfRiBFH"},"source":["class MeanSquaredError:\n","    def compute(self, target, prediction):\n","        esum = 0\n","        delta = np.subtract(target,prediction)\n","        for i in delta:\n","            esum += i ** 2\n","        return esum/len(delta)    \n","    def differentiate(self, prediction, target):\n","        return np.multiply(np.subtract(target, prediction), 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yrDt1RfZFwv9"},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder\n","import numpy as np\n","import math"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"gzZBLkzQDyEU","executionInfo":{"status":"ok","timestamp":1610917607399,"user_tz":-60,"elapsed":884,"user":{"displayName":"Megan S","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDu858PxEQUDqrZcoj5btf9gJmLKNMfWZ9BYczGw=s64","userId":"09773696159346925919"}},"outputId":"38661241-8a99-403e-bdda-150f4b2374c9"},"source":["iris = pd.read_csv(\"/content/drive/MyDrive/minor/python/Iris.csv\")\n","iris = iris.sample(frac=1).reset_index(drop=True) # Shuffle the data\n","iris.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>SepalLengthCm</th>\n","      <th>SepalWidthCm</th>\n","      <th>PetalLengthCm</th>\n","      <th>PetalWidthCm</th>\n","      <th>Species</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10</td>\n","      <td>4.9</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.1</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>19</td>\n","      <td>5.7</td>\n","      <td>3.8</td>\n","      <td>1.7</td>\n","      <td>0.3</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>110</td>\n","      <td>7.2</td>\n","      <td>3.6</td>\n","      <td>6.1</td>\n","      <td>2.5</td>\n","      <td>Iris-virginica</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>135</td>\n","      <td>6.1</td>\n","      <td>2.6</td>\n","      <td>5.6</td>\n","      <td>1.4</td>\n","      <td>Iris-virginica</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>27</td>\n","      <td>5.0</td>\n","      <td>3.4</td>\n","      <td>1.6</td>\n","      <td>0.4</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Id  SepalLengthCm  ...  PetalWidthCm         Species\n","0   10            4.9  ...           0.1     Iris-setosa\n","1   19            5.7  ...           0.3     Iris-setosa\n","2  110            7.2  ...           2.5  Iris-virginica\n","3  135            6.1  ...           1.4  Iris-virginica\n","4   27            5.0  ...           0.4     Iris-setosa\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":130}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KqVB1mFTE7BC","executionInfo":{"status":"ok","timestamp":1610917607400,"user_tz":-60,"elapsed":873,"user":{"displayName":"Megan S","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDu858PxEQUDqrZcoj5btf9gJmLKNMfWZ9BYczGw=s64","userId":"09773696159346925919"}},"outputId":"697b1c6b-fe52-458b-9bdc-685571d91968"},"source":["X = iris[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n","# to numpy array \n","X = np.array(X)\n","X[:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[4.9, 3.1, 1.5, 0.1],\n","       [5.7, 3.8, 1.7, 0.3],\n","       [7.2, 3.6, 6.1, 2.5],\n","       [6.1, 2.6, 5.6, 1.4],\n","       [5. , 3.4, 1.6, 0.4]])"]},"metadata":{"tags":[]},"execution_count":131}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VAGfvZUDFZeJ","executionInfo":{"status":"ok","timestamp":1610917607401,"user_tz":-60,"elapsed":863,"user":{"displayName":"Megan S","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDu858PxEQUDqrZcoj5btf9gJmLKNMfWZ9BYczGw=s64","userId":"09773696159346925919"}},"outputId":"ad970e72-ee5f-4ab2-83b7-a5dc7beece91"},"source":["one_hot_encoder = OneHotEncoder(sparse=False)\n","\n","# One hot encode the species \n","y = iris.Species\n","y = one_hot_encoder.fit_transform(np.array(y).reshape(-1, 1))\n","y[:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [1., 0., 0.]])"]},"metadata":{"tags":[]},"execution_count":132}]},{"cell_type":"code","metadata":{"id":"8aTVeTwsFkvB"},"source":["# Split data up in train/test data and then into train/validation data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iNAZjhZ-GD7u"},"source":["def NeuralNetwork(X_train, y_train, X_val=None, y_val=None, epochs=10, nodes=[], lr=0.15):\n","    hidden_layers = len(nodes) - 1\n","    weights = init_weights(nodes) #weigths initialiseren\n","\n","    for epoch in range(1, epochs + 1):\n","      # Model trainen\n","        weights = train(X_train, y_train, lr, weights)\n","\n","        if(epoch % 20 == 0):\n","            print(\"Epoch {}\".format(epoch))\n","            print(\"Training Accuracy:{}\".format(accuracy(X_train, y_train, weights)))\n","            if X_val.any():\n","                print(\"Validation Accuracy:{}\".format(accuracy(X_val, y_val, weights)))\n","            \n","    return weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZBp_OEcpJhOM"},"source":["def init_weights(nodes):\n","    # Initialize weights with random values in [-1, 1] ook de bias\n","    layers, weights = len(nodes), []\n","    \n","    for i in range(1, layers):\n","        w = [[np.random.uniform(-1, 1) for k in range(nodes[i-1] + 1)]\n","              for j in range(nodes[i])]\n","        weights.append(np.matrix(w))\n","    \n","    return weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IwnRvVMpGiOQ"},"source":["def forwardprop(x, weights, layers):\n","  # de weight inputs \n","    activations, layer_input = [x], x\n","    for j in range(layers):\n","        activation = sig(np.dot(layer_input, weights[j].T))\n","        activations.append(activation)\n","        layer_input = np.append(1, activation) # Augment with bias\n","    \n","    return activations"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Ph51h6JGnnT"},"source":["def backprop(y, activations, weights, layers):\n","    outputFinal = activations[-1]\n","    error = np.matrix(y - outputFinal) # Error at output\n","    \n","    for j in range(layers, 0, -1):\n","        current_activation = activations[j]\n","        \n","        if(j > 1):\n","            # Augment previous activation\n","            previous_activation = np.append(1, activations[j-1])\n","        else:\n","            # First hidden layer, previous ctivation is input without bias\n","            previous_activation = activations[0]\n","        \n","        delta = np.multiply(error, dsig(current_activation))\n","        weights[j-1] += lr * np.multiply(delta.T, previous_activation)\n","\n","        w = np.delete(weights[j-1], [0], axis=1) # Remove bias from weights\n","        error = np.dot(delta, w) # Calculate error for current layer\n","    \n","    return weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"65YnAl0fGzrM"},"source":["def train(X, Y, lr, weights):\n","    layers = len(weights)\n","    for i in range(len(X)):\n","        x, y = X[i], Y[i]\n","        x = np.matrix(np.append(1, x)) # Augment feature vector\n","        \n","        #first go trouhg outputs forward\n","        activations = forwardprop(x, weights, layers)\n","        # then back propagation for weight updating\n","        weights = backprop(y, activations, weights, layers)\n","\n","    return weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GSkp00D5HEm-"},"source":["# Sigmoid of x \n","def sig(x):\n","  return 1 / (1 + np.exp(-x))\n","\n","# Derivative of sigmoid of x\n","def dsig(x):\n","    return np.multiply(x, 1-x)\n","\n","#Relu of x\n","def relu( x):\n","    return x if x > 0 else 0 \n","\n","#Derivative relu of x\n","def drelu( x):\n","    return 1.0 if x > 0 else 0 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bqTjLSggHS40"},"source":["def predict(item, weights):\n","    layers = len(weights)\n","    item = np.append(1, item) # Augment feature vector\n","    \n","    # forward propagation\n","    activations = forwardprop(item, weights, layers)\n","    \n","    outputFinal = activations[-1].A1\n","    index = find_max_activation(outputFinal)\n","\n","    # Initialize prediction vector to zeros\n","    y = [0 for i in range(len(outputFinal))]\n","    y[index] = 1  # set prediciton to 1\n","    \n","    # return prediction vector\n","    return y \n","\n","def find_max_activation(output):\n","    # Find max activation in output\n","    m, index = output[0], 0\n","    for i in range(1, len(output)):\n","        if(output[i] > m):\n","            m, index = output[i], i\n","    \n","    return index"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dzWEovHaHrIa"},"source":["def accuracy(X, Y, weights):\n","    corr_pred = 0\n","    # For every prediction\n","    for i in range(len(X)):\n","        x, y = X[i], list(Y[i])\n","        guess = predict(x, weights)\n","\n","        # Add to corr_pred if prediction is correct\n","        if(y == guess):\n","            corr_pred += 1\n","\n","    return corr_pred / len(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FlNDTcNoH9qU","executionInfo":{"status":"ok","timestamp":1610917611212,"user_tz":-60,"elapsed":4594,"user":{"displayName":"Megan S","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDu858PxEQUDqrZcoj5btf9gJmLKNMfWZ9BYczGw=s64","userId":"09773696159346925919"}},"outputId":"d16b44b3-2113-483a-e4b8-6897e9518dd5"},"source":["features = len(X[0]) # Number of features\n","output = len(y[0]) # Number of outputs / classes\n","\n","layers = [features, 5, 10, output] # Number of nodes in layers\n","lr, epochs = 0.15, 100\n","\n","weights = NeuralNetwork(X_train, y_train, X_val, y_val, epochs=epochs, nodes=layers, lr=lr);"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 20\n","Training Accuracy:0.6666666666666666\n","Validation Accuracy:0.6153846153846154\n","Epoch 40\n","Training Accuracy:0.9824561403508771\n","Validation Accuracy:0.9230769230769231\n","Epoch 60\n","Training Accuracy:0.8245614035087719\n","Validation Accuracy:1.0\n","Epoch 80\n","Training Accuracy:0.9649122807017544\n","Validation Accuracy:0.9230769230769231\n","Epoch 100\n","Training Accuracy:0.7894736842105263\n","Validation Accuracy:1.0\n"],"name":"stdout"}]}]}